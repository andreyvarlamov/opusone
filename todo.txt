TODO:
- More rendering
    - Debug rendering:
        - More bounding shapes: spheres, capsules, wireframe triangles;
        - Make render state management more efficient
    - Consider switching to only one render unit marker type per render unit
    - Some kind of screen-space visualization tools. for example plots
    - Instancing
    
- Collisions
    - Basic AABBs
    - AABB Triangle
    - Basic mouse picking
    
- Improving animation
    - Animation blending
    - Animation states
    - Numerical robustness - eliminate jitter (investigate, might not be such a big problem now)

- Study
    - Look into problems with interpolating matrices more -- is it just lerp vs slerp type of thing, or there's more to it?
        - Is just normlalizing the vector after being multiplied with an interpolated matrix. And is that nlerp?
        - Vertex -> fragment shader linearly interpolates between vertices (and normalized?).
    - Review tangent space again

- Shader/gl infrastructure
    - Hot-reloading
    - A build utility
    - Use uniform buffers
    - Keep track of gl state in software, so don't do redundant gl calls
    - Uniform structs
    - Shader modularity. Includes. How to do common uniforms better.

- DCC/Export/Import
    - Optimize material export in gltf
    - Determine the best export setup (ease of use in dcc + performance)
    - Consider creating a custom Blender exporter
    - Handling edge cases/not quite correct export setup better when importing
    - Should be notified when something is not loaded properly.
        - For example when model is expected to have specular map, but for some reason doesn't





- Scratch:
    - I don't think I need normals or alpha in debug draw vertex spec
    - When to do mipmapping, when not to do mipmapping. Is that the right way to handle more distant objects? S and T axes
    - Sort out the camera stuff after I go through the first pass over collisions
        - Separate look direction, independent of orientation, on every entity?
          ControlledEntity. Camera points to any entity, whether controlled or not. Camera matches the look direction of the entity.
          That way can have a non-controlled entity followed by a camera, and the ControlledEntity not followed by a camera.
        - Should camera be its own entity? How to detach camera, e.g. for level editing?
        - Is it possible to collapse the whole crazy structure with calculating a view matrix differently.
          It seems like I should be able to change the order of operations between translation and rotation, to have a target-camera.
        - Change camera inner structures to collapse complexity. Use quaternion?
        - Camera sliding if not enough room
    - Handle a skinned model in a rest pose better
    - More efficient normal transform matrix calculation (calculate for each bone in software and send in uniform).
    - Normal mapping is not implemented in the shader.
    - Do light calculations in view space.
    - Different types of lights. Multiple lights.
    - Materials. How much specular there is basically. Make it work together with specular mapping
    - Shadows. Implies multi-pass rendering
    - glUniformxx accepts count - can modify the whole array. Do that for bone transforms of skinned meshes
    - More flexible shader parameters:
        - Shade texture when there are vertex colors
        - Ignore vertex color when not desired
        - Ignore texture when not desired
        - Ignore normal map when none.
        - What to do as shader attribute vs what to do as uniform vs what to calculate in shader (e.g. Bitangent).
